---
title: "Homework 3: Samplers"
author: "Hilde Younce"
date: "2024-11-07"
output: html_document
---
# Homework 3: Samplers - Hilde Younce

**Honor Pledge:** On my honor as a student, I have neither given nor received unauthorized aid on this assignment.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(Rmpfr)
library(ggplot2)
library(dplyr)
dat = read.csv("coaldisasters-ds6040.csv")
```

## Part 1: Changepoint detection and samplers

```{r}
# Gibbs sampler (from stubs)
gibbs_sampler = function(iter, dat, a_mu, b_mu, a_lambda, b_lambda){
  
  mu_vec = vector()
  lambda_vec = vector() 
  k_prob_mat = matrix(nrow = iter+1, ncol = 111)
  k_samp_vec = vector()
  #Initialize sampler
  mu_vec[1] = rgamma(1,a_mu, rate  = b_mu)
  lambda_vec[1] = rgamma(1,a_lambda, rate = b_lambda)
  k_prob_mat[1,] = rep(1/111, 111)
  k_samp_vec[1] = 56
  
  #Sampler
  for(i in 2:(iter+1)){
    mu_vec[i] = rgamma(1, a_mu + sum(dat$Count[1:k_samp_vec[i-1]]), k_samp_vec[i-1] + b_mu)
    lambda_vec[i] = rgamma(1, a_lambda + sum(dat$Count[(k_samp_vec[i-1]+1):nrow(dat)]), 
                           112 - k_samp_vec[i-1] + b_lambda)
    
    l_temp = vector()
  for(j in 1:111){  
      l_temp[j] = sum(log(mpfr(dpois(dat[1:j,2], lambda = rep(mu_vec[i],j)), precBits = 100))) +
      sum(log(.mpfr(dpois(dat[(j+1):112,2], lambda = rep(lambda_vec[i],112-j)), precBits = 100)))
    }
    l_temp <- mpfr(l_temp, precBits = 100)
    k_prob_mat[i,] = as.numeric(exp(l_temp)/sum(exp(l_temp))) 
    k_samp_vec[i] = sample(size = 1,1:111, prob = k_prob_mat[i,])
  }
  toReturn = data.frame(mu = mu_vec, lambda = lambda_vec, k = k_samp_vec)
  
  return(toReturn)
}

# Changed number of iterations from 1000 to 500 because R was crashing
test = gibbs_sampler(500, dat, a_mu = 1, b_mu = 1, a_lambda = 1, b_lambda = 1) 

```

```{r}
# Plot posterior densities
test %>% ggplot(aes(x=mu)) + geom_density(fill = "skyblue") + labs(title="Density of Mu")
```
```{r}
test %>% ggplot(aes(x=lambda)) + geom_density(fill = "skyblue") + labs(title="Density of Lambda")
```
```{r}
# EAP and confidence intervals 

# Mu
mu_EAP <- mean(test$mu)
mu_CI <- quantile(test$mu, probs = c(0.025, 0.975))

# Lambda
lambda_EAP <- mean(test$lambda)
lambda_CI <- quantile(test$lambda, probs = c(0.025, 0.975))

cat("EAP estimate for mu:", mu_EAP, "\n")
cat("95% Credible Interval for mu:", mu_CI, "\n")
cat("EAP estimate for lambda:", lambda_EAP, "\n")
cat("95% Credible Interval for lambda:", lambda_CI, "\n")
```
```{r}
# 5 most probable values of k
test$diff = abs(test$mu - test$lambda)
test %>% arrange(desc(diff)) %>% head(5)
```
**a) Describe your findings. What do these EAP and credible intervals imply? And what was the most likely year of the changepoint?** 

Based on the results of the Gibbs sampler, for a given year k the expected value of the rate of coal mining accidents from years 1 to k is 3.06, and there is a 95% probability that an unobserved mu value will fall into the interval (2.51, 3.69). Likewise, for a given year k the expected value of the rate of coal mining accidents from years k+1 to 112 is 0.91, and there is a 95% probability that an unobserved lambda value will fall into the interval (0.71, 1.19). 

We can identify the most probable years where a changepoint occured, we can look at the biggest differences in the rates of coal accidents before and after year k, or equivalently the biggest differences in mu and lambda. Identifying the top five largest differences, we see that when k=40, there is the biggest change between mu and lambda. This indicates that there was likely a changepoint in the year k=40, which was 1890. 

**b) Why is an EAP or credible interval not necessarily the most appropriate thing to report for the year of the changepoint?**

EAP and credible intervals may not provide the best insight when we are trying to locate a changepoint because they give a single summary of the distribution of mu and lambda. Taking a summary over a long period of time may mask specific moments in time where there were drastic changes, and misrepresent the data with a single mean value. Finally, credible intervals offer bounds but do not pinpoint the exact moment of a changepoint. 

## Part 2: Bayesian Logistic Regression with brms

```{r}
library(brms)
library(caret)
```

```{r}
# Load and transform data
wine_train <- read.csv('whitewine-training-ds6040-1.csv')
wine_test <- read.csv('whitewine-testing-ds6040.csv')
wine_train$wine_quality <- ifelse(wine_train$wine_quality == "A", 1, 0)
wine_test$wine_quality <- ifelse(wine_test$wine_quality == "A", 1, 0)
```

```{r}
# Full Logistic Regression Model
log_model <- brm(
  formula = wine_quality~.,
  data = wine_train,
  family = bernoulli(),
  silent = 0
)
summary(log_model)
```

```{r}
predictors <- setdiff(names(wine_test), "wine_quality")
combos <- combn(predictors, 3, simplify = FALSE)

results_df <- data.frame(
  combinations = character(0),
  class_rate = numeric(0),
  class_A_rate = numeric(0)
)
```

```{r}
get_rates<- function(combo){
  formula <- as.formula(paste("wine_quality~", paste(combo, collapse = " + ")))
  log_model <- brm(
    formula = formula,
    data = wine_train,
    family = bernoulli(),
    silent = 0
  )
  
  preds <- fitted(log_model, newdata=wine_test[,!(colnames(wine_test)=="wine_quality")], type = "response")
  preds <- if_else(preds[,1] > 0.1, 1, 0)
  class_rate <- mean(preds==wine_test$wine_quality)
  class_A <- wine_test$wine_quality == 1
  class_A_rate <- mean(preds[class_A] == wine_test$wine_quality[class_A])

  return(list(
    combinations = paste(combo, collapse = ", "),
    class_rate = class_rate,
    class_A_rate = class_A_rate
  ))
}
```

```{r}
for (combo in combos) {
  rates <- get_rates(combo)
  results_df <- rbind(results_df, as.data.frame(rates, stringsAsFactors = FALSE))
}
```


