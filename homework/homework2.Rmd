# Homework 2 - Hilde Younce

```{r}
# install.packages("rstan", repos = c('https://stan-dev.r-universe.dev', getOption("repos")))
library(ggplot2)
library(tidyverse)
library(dirmult)
library(rstan)
```

## Problem 1: Conjugate Priors

```{r}
# Get data 
wine_train <- read.csv('whitewine-training-ds6040.csv')
```

**Density plot 1: residual.sugar**
```{r}
ggplot(wine_train, aes(x=residual.sugar)) + 
  geom_density(fill = "lightblue") + 
  labs(title="Residual Sugar Density")
```

The density plot for residual.sugar does not look very normally distributed. There is a higher density around -1 that declines and then zeros out at around 2.5, and is skewed towards the right. 

**Density plot 2: total.sulfur.dioxide**
```{r}
ggplot(wine_train, aes(x=total.sulfur.dioxide)) + 
  geom_density(fill = "lightblue") + 
  labs(title="Total Sulfur Dioxide Density")
```

The density for total.sulfur.dioxide looks more normal than the density plot for residual.sugar. There looks to be a mean value around -0.5, with a slight skew to the right. 

#### Normal Distribution

```{r}
# Function to calculate posterior
normal_posterior <- function(n, mu, sigma, mu0, tau){
  post_var <- 1 / (1 / sigma + 1 / tau)
  post_mean <- (mu / sigma + mu0 / tau) * post_var
  return (c(post_var, post_mean))
}
```

**Residual sugar: Uninformative prior**
```{r}
n = nrow(wine_train)
mean_sugar <- mean(wine_train$residual.sugar)
var_sugar <- var(wine_train$residual.sugar)

mu0 = 0
tau = 1000 # high variance
post1 <- normal_posterior(n, mean_sugar, var_sugar, mu0, tau)

print(paste("Posterior mean:", post1[1]))
print(paste("Posterior variance:", post1[2]))
```

**Residual sugar: Informative prior**
```{r}
mu0 = 0
tau = 10 # low variance
post2 <- normal_posterior(n, mean_sugar, var_sugar, mu0, tau)

print(paste("Posterior mean:", post2[1]))
print(paste("Posterior variance:", post2[2]))
```

**Total Sulfur Dioxide: Uninformative prior**
```{r}
mean_sulfur <- mean(wine_train$total.sulfur.dioxide)
var_sulfur <- var(wine_train$total.sulfur.dioxide)

mu0 = 0
tau = 1000 # high variance
post3 <- normal_posterior(n, mean_sulfur, var_sulfur, mu0, tau)

print(paste("Posterior mean:", post3[1]))
print(paste("Posterior variance:", post3[2]))
```

**Total Sulfur Dioxide: Informative prior**
```{r}
mu0 = 0
tau = 10 # low variance
post4 <- normal_posterior(n, mean_sulfur, var_sulfur, mu0, tau)

print(paste("Posterior mean", post4[1]))
print(paste("Posterior variance:", post4[2]))
```

**What are the impacts of different hyperparameter choices on the posterior distributions? Is it possible to chose "bad" hyperparameters? If so, why? What are the consequences for inference?**

Hyperparameters effect the amount of influence a prior has on the posterior distribution, and the overall shape of that distribution. In this example, my choice of hyperparameters did not effect the prior distribution heavily, but in theory a highly informative tau value means the prior distribution will be tightly centered around mu0, which will have a stronger influence on the posterior. "Bad" hyperparameter choices are ones that do not fit the data or distribution you are working with, like choosing highly informative priors when we lack prior knowledge of our parameters. In inference, this can lead to the posterior being constricted and hiding insights or misrepresenting reality. 

#### Exponential Distribution:

```{r}
# Function to calculate posterior
exp_posterior <- function(n, sum, alpha0, beta0){
  post_alpha <- alpha0 + n
  post_beta <- beta0 + sum
  return (c(post_alpha, post_beta))
}
```

**Residual sugar: Uninformative prior**
```{r}
sum_sugar <- sum(wine_train$residual.sugar)

alpha0 <- 1
beta0 <- 0.01
post1 <- exp_posterior(n, sum_sugar, alpha0, beta0)
post_alpha <- post1[1]
post_beta <- post1[2]

print(paste("Posterior mean:", post_alpha / post_beta))
print(paste("Posterior variance:", post_alpha / (post_beta^2)))
```

**Residual sugar: Informative prior**
```{r}
alpha0 <- 10
beta0 <- 5
post2 <- exp_posterior(n, sum_sugar, alpha0, beta0)
post_alpha <- post2[1]
post_beta <- post2[2]

print(paste("Posterior mean:", post_alpha / post_beta))
print(paste("Posterior variance:", post_alpha / (post_beta^2)))
```

**Total sulfur dioxide: Uninformative prior**
```{r}
sum_sulfur <- sum(wine_train$total.sulfur.dioxide)

alpha0 <- 1
beta0 <- 0.01
post3 <- exp_posterior(n, sum_sulfur, alpha0, beta0)
post_alpha <- post3[1]
post_beta <- post3[2]

print(paste("Posterior mean:", post_alpha / post_beta))
print(paste("Posterior variance:", post_alpha / (post_beta^2)))
```

**Total sulfur dioxide: Informative prior**
```{r}
alpha0 <- 10
beta0 <- 5
post4 <- exp_posterior(n, sum_sulfur, alpha0, beta0)
post_alpha <- post4[1]
post_beta <- post4[2]

print(paste("Posterior mean:", post_alpha / post_beta))
print(paste("Posterior variance:", post_alpha / (post_beta^2)))
```

**Again, what are the impacts of the hyperparameter choice?**

In this example, our hyperparameter choice had a very significant effect on our posterior distribution. Uninformative hyperparameter choices led to a much higher mean and variance, meaning that we get different distributions and shapes of our posterior across hyperparameters. 

**How do these values differ from the values you found when using a normal distribution as the likelihood?**

They are much much larger. 


## Problem 2: Multinomial Prios

**Looking at the above formula for the posterior distribution, how can you interpret the meaning of α?**

Since α is a vector of hyperparameter choices for each category, we can interpret alpha like a vector of weights that represents our belief in the probability of each category. If we choose the same alpha for all categories, we are imposing an uninformative prior that assumes all categories are equally likely to occur. 

```{r}
# Get n vector
counts <- table(wine_train$wine_quality)
n <- c(counts[[1]], counts[[2]], counts[[3]])
```

**Uninformative Prior**
```{r}
alphas <- c(1,1,1)
post_uninform <- data.frame(rdirichlet(1000, alphas + n))
post_uninform <- rename(post_uninform,"A" = X1, "C" = X2, "F" = X3)
head(post_uninform)
```

**Informative Prior**
```{r}
alphas <- c(5,50,10) # Based on category counts in dataset
post_inform <- data.frame(rdirichlet(n=1000, alphas + n))
post_inform <- rename(post_inform, "A" = X1, "C" = X2, "F" = X3)
head(post_inform)
```

**Boxplot 1: Uninformative**
```{r}
uninform_long <- pivot_longer(post_uninform, cols = everything(), names_to = "Grade", values_to = "Value")
ggplot(uninform_long, aes(x = Grade, y = Value, color = Grade)) +
  geom_boxplot() +
  labs(title = "Uninformative Hyperparameter")
```

**Boxplot 2: Informative**
```{r}
inform_long <- pivot_longer(post_inform, cols = everything(), names_to = "Grade", values_to = "Value")
ggplot(inform_long, aes(x = Grade, y = Value, color = Grade)) + 
  geom_boxplot() +
  labs(title = "Informative Hyperparameter")
```

I'm not sure if I made a mistake somewhere in my code or if this is the expected result, because it looks like my hyperparameter choice had very little effect on my posterior distributions for each letter grade. The boxplots for the uninformative prior and informative prior are practically identical, and remained so even when I tested a range of different alpha vectors. 


## Problem 3: Bayesian Inference

**Grade A: Uninformative**
```{r}
df_a <- wine_train[wine_train$wine_quality == "A",]
mean_a <- mean(df_a$alcohol)
var_a <- var(df_a$alcohol)

mu0 = 0
tau = 10 # low variance
post_a_uninform <- normal_posterior(n, mean_a, var_a, mu0, tau)

print(paste("Posterior mean:", post_a_uninform[1]))
print(paste("Posterior variance:", post_a_uninform[2]))
```

**Grade A: Informative**
```{r}
mu0 = 0
tau = 1000 # high variance
post_a_inform <- normal_posterior(n, mean_a, var_a, mu0, tau)

print(paste("Posterior mean:", post_a_inform[1]))
print(paste("Posterior variance:", post_a_inform[2]))
```

**Grade F: Uninformative**
```{r}
df_f <- wine_train[wine_train$wine_quality == "F",]
mean_f <- mean(df_f$alcohol)
var_f <- var(df_f$alcohol)

mu0 = 0
tau = 10 # low variance
post_f_uninform <- normal_posterior(n, mean_f, var_f, mu0, tau)

print(paste("Posterior mean:", post_f_uninform[1]))
print(paste("Posterior variance:", post_f_uninform[2]))
```

**Grade F: Informative**
```{r}
mu0 = 0
tau = 1000 # high variance
post_f_inform <- normal_posterior(n, mean_f, var_f, mu0, tau)

print(paste("Posterior mean:", post_f_inform[1]))
print(paste("Posterior variance:", post_f_inform[2]))
```

**Difference: Uninformative**
```{r}
mu_uninform <- post_a_uninform[1] - post_f_uninform[1]
var_uninform <- post_a_uninform[2] + post_f_uninform[2]

print(paste("Posterior mean of the difference:", mu_uninform))
print(paste("Posterior variance of the difference:", var_uninform))
```

**Difference: Informative**
```{r}
mu_inform <- post_a_inform[1] - post_f_inform[1]
var_inform <- post_a_inform[2] + post_f_inform[2]

print(paste("Posterior mean of the difference:", mu_inform))
print(paste("Posterior variance of the difference:", var_inform))
```

**95% HDI: Uninformative**
```{r}
lower_bound <- mu_uninform - 1.96 * var_uninform
upper_bound <- mu_uninform + 1.96 * var_uninform

cat("95% HDI: [", lower_bound, ", ", upper_bound, "]\n")
```

**95% HDI: Informative**
```{r}
lower_bound <- mu_inform - 1.96 * var_inform
upper_bound <- mu_inform + 1.96 * var_inform

cat("95% HDI: [", lower_bound, ", ", upper_bound, "]\n")
```

**What does this interval tell you about the difference between the alcohol quantities in the two grades of wine? Would you consider the alcohol content to be 'significantly' different?**

For our uninformative priors, we had a 95% HDI of [-0.07347578, 1.038092]. Since this interval includes zero, though narrowly, this leaves the possibility that there is no difference in the means of alcohol content across grade A and grade F wines. However, since our interval is wide, with an upper bound of 1.038, there is a credible range that suggests the alcohol content in grade A wine can be up to 1 units higher than alcohol content in grade F wine. Because 0 is very close to our lower bound, I would consider the mean alcohol content to be significantly different across grades of wine. 

Similarly, for the informative priors, we had a 95% HDI of [-0.1117743, 1.234717], a slightly wider range. Again, the interval includes zero so there may be no difference in means of alcohol content. However, for the same reasoning applied to the uninformative prior interval, I would still consider the alcohol content to be statistically significant. 

**How does prior choice impact this?**

Since we chose a larger variance for our informative prior, this lead to a higher variance and slightly higher mean in our posterior distribution and therefore a wider range of values in our density interval. 


## Extra Credit:

**Uninformative choices**
```{r}
rstan_options(auto_write = TRUE)

N1 = 100 # number of grade A observations
N2 = 1000 # number of grade F observations

y1 = as.vector(df_a$alcohol)
y2 = as.vector(df_f$alcohol)

# uninformative hyperparameters
mu_sd1 = 10 
sigma_scale1 = 10
mu_sd2 = 10
sigma_scale2 = 10

dat_list1 = list(N1=N1, N2=N2, y1=y1, y2=y2, mu_sd1=mu_sd1, mu_sd2=mu_sd2, 
                 sigma_scale1=sigma_scale1, sigma_scale2=sigma_scale2)

results1 = stan(file="homework2.stan", data=dat_list1)
```

**Informative choices:**
```{r}
# informative hyperparameters
mu_sd1 = 1000 
sigma_scale1 = 2
mu_sd2 = 1000
sigma_scale2 = 2

dat_list2 = list(N1=N1, N2=N2, y1=y1, y2=y2, mu_sd1=mu_sd1, mu_sd2=mu_sd2, 
                 sigma_scale1=sigma_scale1, sigma_scale2=sigma_scale2)

results2 = stan(file="homework2.stan", data=dat_list2)
```

**Plot posterior distributions of differences in means:**
```{r}
mu_samples1 <- extract(results1)$mu_diff
mu_samples2 <- extract(results2)$mu_diff
```

```{r}
posterior_df <- data.frame(
  difference = c(mu_samples1, mu_samples2),
  type = rep(c("Uninformative", "Informative"), each = length(mu_samples1))
)

ggplot(posterior_df, aes(x = difference, fill = type)) +
  geom_density(alpha = 0.5) +
  labs(title = "Posterior Distributions of the Difference in Means")
```

**How are these posteriors different/similar to those from the original analyses where we specified the variances as known? What was the impact of priors here?**

These posteriors are different than when specifying a known variance because using a prior for variance introduces more uncertainty into our posterior distributions. The posterior distribution reflects knowledge from the prior and observed data, rather than just the observed data. This leads to our distribution being wider or having greater tails. In this case, the uninformative priors led to a greater density around the mean and a slightly more narrow distribution than the informative priors. 




