# Homework 2 - Hilde Younce

```{r}
# install.packages("rstan", repos = c('https://stan-dev.r-universe.dev', getOption("repos")))
library(ggplot2)
library(tidyverse)
library(dirmult)
library(rstan)
```

## Problem 1: Conjugate Priors

```{r}
# Get data 
wine_train <- read.csv('whitewine-training-ds6040.csv')
```

```{r}
# Density plot 1: residual.sugar
ggplot(wine_train, aes(x=residual.sugar)) + 
  geom_density(fill = "lightblue") + 
  labs(title="Residual Sugar Density")
```

The density plot for residual.sugar does not look very normally distributed. There is a higher density around -1 that declines and then zeros out at around 2.5, and is skewed towards the right. 

```{r}
# Density plot 2: total.sulfur.dioxide
ggplot(wine_train, aes(x=total.sulfur.dioxide)) + 
  geom_density(fill = "lightblue") + 
  labs(title="Total Sulfur Dioxide Density")
```

The density for total.sulfur.dioxide looks more normal than the density plot for residual.sugar. There looks to be a mean value around -0.5, with a slight skew to the right. 

#### Normal Distribution

```{r}
# Function to calculate posterior
normal_posterior <- function(n, mu, sigma, mu0, tau){
  post_var <- 1 / (1 / sigma + 1 / tau)
  post_mean <- (mu / sigma + mu0 / tau) * post_var
  return (c(post_var, post_mean))
}
```


```{r}
# Residual sugar - uninformative prior
n = nrow(wine_train)
mean_sugar <- mean(wine_train$residual.sugar)
var_sugar <- var(wine_train$residual.sugar)

mu0 = 0
tau = 1000 # high variance
post1 <- normal_posterior(n, mean_sugar, var_sugar, mu0, tau)

print(paste("Posterior mean:", post1[1]))
print(paste("Posterior variance:", post1[2]))
```

```{r}
# Residual sugar - informative prior
mu0 = 0
tau = 10 # low variance
post2 <- normal_posterior(n, mean_sugar, var_sugar, mu0, tau)

print(paste("Posterior mean:", post2[1]))
print(paste("Posterior variance:", post2[2]))
```

```{r}
# Total Sulfur Dioxide - uninformative prior
mean_sulfur <- mean(wine_train$total.sulfur.dioxide)
var_sulfur <- var(wine_train$total.sulfur.dioxide)

mu0 = 0
tau = 1000 # high variance
post3 <- normal_posterior(n, mean_sulfur, var_sulfur, mu0, tau)

print(paste("Posterior mean:", post3[1]))
print(paste("Posterior variance:", post3[2]))
```

```{r}
# Total Sulfur Dioxide - informative prior
mu0 = 0
tau = 10 # low variance
post4 <- normal_posterior(n, mean_sulfur, var_sulfur, mu0, tau)

print(paste("Posterior mean", post4[1]))
print(paste("Posterior variance:", post4[2]))
```

**What are the impacts of different hyperparameter choices on the posterior distributions? Is it possible to chose "bad" hyperparameters? If so, why? What are the consequences for inference?**

Hyperparameters effect the amount of influence a prior has on the posterior distribution, and the overall shape of that distribution. In this example, my choice of hyperparameters did not effect the prior distribution heavily, but in theory a highly informative tau value means the prior distribution will be tightly centered around mu0, which will have a stronger influence on the posterior. "Bad" hyperparameter choices are ones that do not fit the data or distribution you are working with, like choosing highly informative priors when we lack prior knowledge of our parameters. In inference, this can lead to the posterior being constricted and hiding insights or misrepresenting reality. 

#### Exponential Distribution:

```{r}
# Function to calculate posterior
exp_posterior <- function(n, sum, alpha0, beta0){
  post_alpha <- alpha0 + n
  post_beta <- beta0 + sum
  return (c(post_alpha, post_beta))
}
```

```{r}
# Residual sugar - uninformative prior
sum_sugar <- sum(wine_train$residual.sugar)

alpha0 <- 1
beta0 <- 0.01
post1 <- exp_posterior(n, sum_sugar, alpha0, beta0)
post_alpha <- post1[1]
post_beta <- post1[2]

print(paste("Posterior mean:", post_alpha / post_beta))
print(paste("Posterior variance:", post_alpha / (post_beta^2)))
```

```{r}
# Residual sugar - informative prior
alpha0 <- 10
beta0 <- 5
post2 <- exp_posterior(n, sum_sugar, alpha0, beta0)
post_alpha <- post2[1]
post_beta <- post2[2]

print(paste("Posterior mean:", post_alpha / post_beta))
print(paste("Posterior variance:", post_alpha / (post_beta^2)))
```

```{r}
# Total sulfur dioxide - uninformative prior
sum_sulfur <- sum(wine_train$total.sulfur.dioxide)

alpha0 <- 1
beta0 <- 0.01
post3 <- exp_posterior(n, sum_sulfur, alpha0, beta0)
post_alpha <- post3[1]
post_beta <- post3[2]

print(paste("Posterior mean:", post_alpha / post_beta))
print(paste("Posterior variance:", post_alpha / (post_beta^2)))
```

```{r}
# Total sulfur dioxide - informative prior
alpha0 <- 10
beta0 <- 5
post4 <- exp_posterior(n, sum_sulfur, alpha0, beta0)
post_alpha <- post4[1]
post_beta <- post4[2]

print(paste("Posterior mean:", post_alpha / post_beta))
print(paste("Posterior variance:", post_alpha / (post_beta^2)))
```

**Again, what are the impacts of the hyperparameter choice?**

In this example, our hyperparameter choice had a very significant effect on our posterior distribution. Uninformative hyperparameter choices led to a much higher mean and variance, meaning that we get different distributions and shapes of our posterior across hyperparameters. 

**How do these values differ from the values you found when using a normal distribution as the likelihood?**

They are much much larger. 


## Problem 2: Multinomial Prios

**Looking at the above formula for the posterior distribution, how can you interpret the meaning of α?**

Since α is a vector of hyperparameter choices for each category, we can interpret alpha like a vector of weights that represents our belief in the probability of each category. If we choose the same alpha for all categories, we are imposing an uninformative prior that assumes all categories are equally likely to occur. 

```{r}
# Get n vector
counts <- table(wine_train$wine_quality)
n <- c(counts[[1]], counts[[2]], counts[[3]])
```

```{r}
# Uninformative hyperparameter
alphas <- c(1,1,1)
post_uninform <- data.frame(rdirichlet(1000, alphas + n))
post_uninform <- rename(post_uninform,"A" = X1, "C" = X2, "F" = X3)
head(post_uninform)
```

```{r}
# Informative Prior 
alphas <- c(5,50,10) # Based on category counts in dataset
post_inform <- data.frame(rdirichlet(n=1000, alphas + n))
post_inform <- rename(post_inform, "A" = X1, "C" = X2, "F" = X3)
head(post_inform)
```

```{r}
# Boxplot 1: Uninformative 
uninform_long <- pivot_longer(post_uninform, cols = everything(), names_to = "Grade", values_to = "Value")
ggplot(uninform_long, aes(x = Grade, y = Value, color = Grade)) +
  geom_boxplot() +
  labs(title = "Uninformative Hyperparameter")
```

```{r}
# Boxplot 2: Informative
inform_long <- pivot_longer(post_inform, cols = everything(), names_to = "Grade", values_to = "Value")
ggplot(inform_long, aes(x = Grade, y = Value, color = Grade)) + 
  geom_boxplot() +
  labs(title = "Informative Hyperparameter")
```

I'm not sure if I made a mistake somewhere in my code or if this is the expected result, because it looks like my hyperparameter choice had very little effect on my posterior distributions for each letter grade. The boxplots for the uninformative prior and informative prior are practically identical, and remained so even when I tested a range of different alpha vectors. 
